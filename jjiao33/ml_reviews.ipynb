{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/junyi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/junyi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/junyi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import sys\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from random import shuffle\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk.util import ngrams\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseReview(line):\n",
    "    if line[1] == \"__label1__\":\n",
    "        s = \"fake\"\n",
    "    else:\n",
    "        s = \"real\"\n",
    "    return (line[0], line[2], line[3], line[4], line[8], s)\n",
    "\n",
    "def preProcess(text):\n",
    "    m = {key: \"\" for key in string.punctuation}\n",
    "    #table = string.maketrans(m)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered_tokens=[]\n",
    "    lemmatized_tokens = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = text.translate(m)\n",
    "    for w in text.split(\" \"):\n",
    "        if w not in stop_words:\n",
    "            lemmatized_tokens.append(lemmatizer.lemmatize(w.lower()))\n",
    "        filtered_tokens = [' '.join(l) for l in nltk.bigrams(lemmatized_tokens)] + lemmatized_tokens\n",
    "    return filtered_tokens\n",
    "\n",
    "def loadData(path, rawData):\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        next(reader)\n",
    "        categories = {}\n",
    "        ind = 0\n",
    "        for line in reader:\n",
    "            (Id, rating, verified_purchase, product_category, text, Label) = parseReview(line)\n",
    "            if product_category not in categories:\n",
    "                category = ind\n",
    "                categories[product_category] = ind\n",
    "                ind += 1\n",
    "            vp = 1 if verified_purchase == 'Y' else 0\n",
    "\t    filtered_tokens = preProcess(unicode(text, 'utf-8'))\n",
    "            rawData.append(' '.join(filtered_tokens))\n",
    "\n",
    "def processData(rawData):\n",
    "    shuffle(rawData)\n",
    "    X = []\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(rawData)\n",
    "    X = X.toarray()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = []\n",
    "featureDict = defaultdict(int)\n",
    "loadData('reviews_4000.txt', rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processData(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate of GaussianMixture with kmeans init\n"
     ]
    }
   ],
   "source": [
    "clusters = [\n",
    "               (GaussianMixture, 'kmeans', {'covariance_type':'full'}),             \n",
    "           ]\n",
    "sample_size = [100, 300, 900, 1800, 4000]\n",
    "max_iters = np.array([1, 125,  250, 500, 750, 875, 1000])\n",
    "clf_error = {}\n",
    "plt.figure()\n",
    "legends = []\n",
    "starttime = time.time()\n",
    "for factory, init, params in clusters:\n",
    "    print('Evaluate of {} with {} init'.format(factory.__name__, init))\n",
    "    for size in sample_size:\n",
    "        inertia = np.empty(len(max_iters))\n",
    "        for i, max_iter in enumerate(max_iters):\n",
    "            km = factory(n_components=2, init_params = init, max_iter=max_iter, n_init=2, **params).fit(X)\n",
    "            inertia[i] = km.inertia_ \n",
    "        plt.plot(max_iters, inertia)\n",
    "        legends.append(\"{} with size = {}\".format(factory.__name__, size))\n",
    "    fig = plt.gcf()\n",
    "    ax = plt.gca()\n",
    "    plt.title(factory.__name__)\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.legend(legends)\n",
    "    fig.savefig(factory.__name__+'2')\n",
    "print('running time is {} s'.format(time.time()-starttime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
